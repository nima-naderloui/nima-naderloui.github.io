---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
/* Shared section styling */
.section {
  margin-top: 2.5em;
  padding-top: 1em;
  border-top: 1px solid #ddd;
}

/* Section headers with underline */
.section h2 {
  font-size: 1.3em;
  margin-bottom: 0.75em;
  padding-bottom: 0.3em;
  border-bottom: 1px solid #ccc;
  font-weight: 600;
}

/* News box styles */
.news-box {
  max-height: 150px;
  overflow-y: auto;
  padding-left: 1em;
  font-size: 0.95em;
  line-height: 1.6;
}
.news-box li {
  margin-bottom: 0.75em;
}

/* Education box styles */
.edu-box {
  padding-left: 1em;
  font-size: 0.95em;
  line-height: 1.6;
}
.edu-box li {
  margin-bottom: 0.75em;
  list-style-type: none;
  display: flex;
  align-items: center;
}
.edu-box img {
  width: 20px;
  height: auto;
  margin-right: 8px;
  flex-shrink: 0;
}

/* Link styles */
a {
  color: #1a73e8;
  text-decoration: none;
}
a:hover {
  text-decoration: underline;
}
</style>

<!-- About Me -->
<div class="section">
  <h2>ğŸ‘‹ About Me</h2>
  <p>I'm Nima, (Farsi: Ù†ÛŒÙ…Ø§). I'm a 2nd-year PhD student at the Computer Science and Eng. department of UConn, where I am advised by <a href="https://yhongcs.github.io/">Prof. Yuan Hong</a> and a member of <a href="https://yhongcs.github.io/people.html">DataSec Lab</a>.</p>

I'm interested in deeply understanding how AI models behave and are applied in practice. I'm passionate about investigating the privacy and safety risks of AI systems, particularly those stemming from design choices, model behaviors, and deployment strategies. Right now, Iâ€™m all about digging into AI models ğŸ•µï¸â€â™‚ï¸, finding what breaks, and uncovering hidden vulnerabilities that others might miss â€” but always curious and open to learning how to patch things up ğŸ› ï¸ when needed. Please contact me if you had any ideas we can discuss!</p>
</div>

<!-- News Section -->
<div class="section">
  <h2>ğŸ—ï¸ News</h2>
  <div class="news-box">
    <ul>
      <li><strong>June 2025</strong> â€“ Our paper on "<em>unlearning evaluation</em>" was accepted at <strong>USENIX Security '25</strong </li>
        <a href="https://www.arxiv.org/abs/2506.13009" target="_blank">arXiv</a> | 
        <a href="https://github.com/datasec-lab/Ruli" target="_blank">Code</a>
      </li>
      <li><strong>December 2024</strong> â€“ Passed the Qualifying Exam.</li>
      <li><strong>April 2024</strong> â€“ Awarded the Synchrony Fellowship for Spring 2024.</li>
    </ul>
  </div>
</div>

<!-- Education Section -->
<div class="section">
  <h2>ğŸ“ Education</h2>
  <div class="edu-box">
    <ul>
      <li>
        <img src="/images/uconn.png" alt="UConn Logo">
        <div><strong>Ph.D. in Computer Science</strong>, University of Connecticut (Sep 2023 â€“ Present)</div>
      </li>
      <li>
        <img src="/images/kntu.png" alt="KNTU Logo">
        <div><strong>B.Sc. in Electrical Engineering</strong>, K.N. Toosi University of Technology (2017 â€“ 2022)</div>
      </li>
    </ul>
  </div>
</div>

<!-- Service Section -->
<div class="section">
  <h3> Service</h3>
  <ul>
    <li><strong> Artifact Evaluation Committee</strong>, ACM CCS 2025
    <li><strong> Reviewer, AAAI 2024
    <li><strong>External Reviewer</strong>, USENIX Security 2025, 2024, 2023; ACM CCS 2025, 2024; NDSS 2025, 2024; IEEE S&P 2024; KDD 2025; CVPR 2024</li>
  </ul>
</div>

